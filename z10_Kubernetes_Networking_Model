z10_Kubernetes_Networking_Model
===============================

KUBERNETES NETWORK MODEL
------------------------
- TL,DR
- our cluster (nodes & pods) is 1 big flat IP network
- in detail :
  - all nodes must be able to reach each other, without NAT
  - all pods must be able to reach each other, without NAT
  - pods & nodes must be able to reach each other, without NAT
  - each pod is aware of its IP address (no NAT)
  -pod IP addresses are assigned by the network implementation
- K8s does NOT mandate any particular implementation


K8s Network Model : The Good
----------------------------
- everything can reach everything
- no address translation
- no port translation
- no new protocol
- the network implementation can decide how to allocate addresses
- IP addresses don't have to be "portable" from a node to another
  - eg we can use a subnet per node and use a simple routed topology
- the specification is simple enough to allow many various implementations


K8s Network Model : The Less Good
---------------------------------
- everything can reach everything
  - if you want security, you need to add network policies
  - the network implementation you use needs to support them
- there are literally dozens of implementations out there
  - 15 are listed in K8s documentation
- pods have level 3 (IP) connectivity, but services are level 4 (TCP or UDP)
  - services map to a single UDP or TCP port; no port ranges or arbitrary IP packets
- kube-proxy is on the data path when connecting to a pod or container, and it's not particularly fast
  - relies on userland proxying or iptables


K8s Network MODEL
-----------------
- the nodes we are using have been set up to use kubenet, Calico, or something else
- don't worry about the warning about kube-proxy performance
- unless you :
  - routinely saturate 10G network interfaces
  - count packet rates in millions per second
  - run high-traffic VOIP or gaming platforms
  - do weird things that involve millions of simultaneous connections
    - in which case you're already familiar with fine-tuning
- if necessary, there are alternatives to kube-proxy, eg kube-router


Container Network Interface: CNI Basics
---------------------------------------
- most K8s clusters use CNI "plugins" to implement networking
- when a pod is created, K8s delegates the network setup to these plugins
  - it can be a single plugin, or a combination of plugins, each doing 1 task
- typically, CNI plugins will :
  - allocate an IP address by calling an IPAM {IP Address Management} plugin
  - add a network interface into the pod's network namespace
  - configure the interface as well as required routes, etc


Multiple Moving Parts
---------------------
- the "pod to pod network" or "pod network"
  - provides communication between pods and nodes
  - is generally implemented by CNI plugins
- the "pod to service network" :
  - provides internal communication and load balancing
  - is generally implemented with kube-proxy (or maybe kube-router)
- Network policies :
  - provide firewalling and isolation
  - can be bundled with the "pod network" or provided by another component


Even more Moving Parts
----------------------
- inbound traffic can be handled by multiple components :
  - something like kube-proxy or kube-router (for NodePort services)
  - load balancers - ideally, connected to the pod network
- it is possible to use multiple pod networks in parallel
  - with "meta-plugins" like CNI-Genie or Multus
- Some solutions can fill multiple roles
  - eg kube-router can be set up to provide the pod network and/or network policies and/or replace kube-proxy


ASSIGNMENT 2 : Deployments with SERVICES
----------------------------------------
1. Create a deployment called littletomcat using the tomcat image.
kubectl create deployment littletomcat --image=tomcat


2. What command will help you get the IP address of that Tomcat server?
List all pods with label app=littletomcat, with extra details including IP address:
kubectl get pods --selector=app=littletomcat -o wide
You could also describe the pod:
kubectl describe pod littletomcat-XXX-XXX


3. What steps would you take to ping it from another container?
(Use the shpod environment if necessary)
One way to start a shell inside the cluster: curl https://shpod.sh | sh
Then the IP address of the pod should ping correctly.
You could also start a deployment or pod temporarily (like nginx), then exec in, install ping, and ping the IP.


4. What command would delete the running pod inside that deployment?
We can delete the pod with:
kubectl delete pods --selector=app=littletomcat
or copy/paste the exact pod name and delete it.


5. What happens if we delete the pod that holds Tomcat, while the ping is running?
If we delete the pod, the following things will happen:
- the pod will be gracefully terminated
- the ping command that we left running will fail
- the replica set will notice that it doesn't have the right count of pods and create a replacement pod
- that new pod will have a different IP address (so the ping command won't recover)


6. What command can give our Tomcat server a stable DNS name and IP address?
(An address that doesn't change when something bad happens to the container)
We need to create a Service for our deployment, which will have a ClusterIP that is usable from within the cluster.
One way is with :
- kubectl expose deployment littletomcat --port=8080
(The Tomcat image is listening on port 8080 according to Docker Hub)
Another way is with :
- kubectl create service clusterip littletomcat --tcp 8080


7. What commands would you run to connect to Tomcat with that IP address?
(Use the shpod environment if necessary)
In a shpod environment, we could:
- Install curl in Alpine
apk add curl
- Make a request to the littletomcat service
curl http://littletomcat:8080


8. If we delete the pod that holds Tomcat, does the IP address still work? How could we test that?
Yes. If we delete the pod, another will be created to replace it. The ClusterIP will still work.
(Except during a short period while the replacement container is being started)
